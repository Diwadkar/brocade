For each sample, the following programs were run to generate the data necessary to create this report. Written as for unstranded paired-end data. For single-end reads, R2s and insert size metrics would be omitted. <br> 

> java -Xmx1024m TrimmomaticPE -phred33 [raw_sample_R1] [raw_sample_R2] [sample_R1] [sample_R1_unpaired] [sample_R2] [sample_R2_unpaired] HEADCROP:[bases to trim, if any] ILLUMINACLIP:[sample_primer_fasta]:2:30:10 MINLEN:50<br> <br>
> fastqc [sample_R1] [sample_R2] <br> <br>
> cat [sample_R1/R2] | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(count[read]==1){unique++}};print total,unique,unique*100/total}' <br>


The bwa-mem is used for alignment, and the outputs are piped into samtools for sorting and indexing:<br>

> bwa-mem --t 12 BWA_index_prefix [sample_R1 fastq file] [sample_R2 fastq file] | view -S -b - | samtools sort -@12 -T [sample.tmp] -o [sample.bam] -  <br>


Obtain QC metrics from aligned output files [sample].bam:<br>

> samtools idxstats accepted_hits.sorted.bam > accepted_hits.sorted.stats <br><br>
> bamtools stats -in accepted_hits.sorted.bam > accepted_hits.sorted.bamstats <br><br>
> java -Xmx2g -jar CollectInsertSizeMetrics.jar HISTOGRAM_FILE=InsertSizeHist.pdf INPUT=accepted_hits.sorted.bam OUTPUT=InsertSizeMetrics <br>

Use macs2 for peak calling:<br>

> macs2 callpeak -c [DNA input sample].bam -t [sample].bam -n GR_1D --outdir [sample] -f BAM -g hs -B -q 0.01

```{r, eval=T, echo=F, message=F}
bamstats.data <- read.table(paste(project_name,"_bamstats_counts.txt", sep=""), header=T, as.is=T, sep="\t")
counts.data <- read.table(paste(project_name,"_counts.txt", sep=""), header=T, sep="\t")
if (library_type %in% c("PE")) {
	insert.summary.data <- read.table(paste(project_name,"_insertmetrics_summary.txt", sep=""), header=T, as.is=T, sep="\t")
	insert.metrics.data <- data.frame(c(0:1))
	names(insert.metrics.data) <- "Insert_Size"
	for (i in c(1:length(sample_names))){
		curr.hist.data <- read.table(paste(project_name,"_",sample_names[i],"_insertmetrics_hist.txt", sep=""), header=T, as.is=T, sep="\t")
		insert.metrics.data <- merge(insert.metrics.data, curr.hist.data, all=TRUE)
	}
}
unique.counts.data <- read.table(paste(project_name,"_unique_counts.txt", sep=""), header=T, sep="\t")
duplicates <- read.table(paste(project_name,"_duplicates.txt", sep=""), header=T, sep="\t", as.is=T)
```


```{r lib, echo=F, message=F, warnings=F}
library(RColorBrewer)
library(DT)
library(dplyr)
library(tidyr)
library(ggplot2)
library(pander)
library(DiffBind)
```

## Summary Read Numbers 

The number of raw reads correspond to those that passed Casava QC filters,
were trimmed to remove adaptors by Trimmomatic, and were aligned by BWA to ref_genome. Unique read counts were obtained by using awk on trimmed fastq files. FastQC estimates of percentage of sequences remaining after deduplication were retrieved from fastqc_data.txt files. Bamtools statistics were based on sorted and indexed bam files. The mapped reads were those that mapped to reference and were output by BWA to [sample].bam. Some reads may be mapped to multiple locations in the genome so that the number of total reads reported by bamstats may be greater than the number of raw reads. Related text files that were saved:


```{r, eval=T, echo=F, message=FALSE, results='asis'}
cat(project_name, "_read_counts.txt\n\n", project_name, "_duplicates.txt\n\n", project_name, "_unique_counts.txt\n\n", project_name, "_bamstats_counts.txt\n\n")
```

### Total Number of Raw Reads Summary

```{r, eval=T, echo=F, message=FALSE}
if (library_type %in% c("PE")) {
	R1_dups = duplicates[1, seq(2, length(duplicates[1, ]), 2)]
	unique.counts.data.2 <- cbind(unique.counts.data, t(R1_dups))
	R2_dups = duplicates[1, seq(3, length(duplicates[1, ]), 2)] 
	unique.counts.data.2 <- cbind(unique.counts.data.2, t(R2_dups))
	row.names(unique.counts.data.2) <- c(1:length(row.names(unique.counts.data.2)))
	names(unique.counts.data.2)[-c(1:ncol(unique.counts.data))] <- c("Fastqc_Total_Deduplicated_Percentage_R1", "Fastqc_Total_Deduplicated_Percentage_R2")
	unique.counts.data.2$R1_Percent_Unique <- round(unique.counts.data.2$R1_Percent_Unique, 2) #else get a ton of decimal points
	unique.counts.data.2$R2_Percent_Unique <- round(unique.counts.data.2$R2_Percent_Unique, 2) #else get a ton of decimal points
	unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R1 <- round(unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R1, 2)
	unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R2 <- round(unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R2, 2)
	} else {
	unique.counts.data.2 <- cbind(unique.counts.data, t(duplicates[1, c(2:length(duplicates[1, ]))]))
	row.names(unique.counts.data.2) <- c(1:length(row.names(unique.counts.data.2)))
	names(unique.counts.data.2)[-c(1:ncol(unique.counts.data))] <- "Fastqc_Total_Duplicate_Estimate"
	unique.counts.data.2$Percent_Unique <- round(unique.counts.data.2$Percent_Unique, 2) #else get a ton of decimal points
	unique.counts.data.2$Fastqc_Total_Duplicate_Estimate <- round(unique.counts.data.2$Fastqc_Total_Duplicate_Estimate, 2)
	}
DT::datatable(unique.counts.data.2, rownames = FALSE, options = list(pageLength = 25))
```

### Plot: Percentage of Unique Reads in Original Fastq File

```{r, eval=T, echo=F, message=FALSE, warning=FALSE, fig.width=10, fig.height=8}
par(mai=c(1.02,1,0.82,2.5))
if (library_type %in% c("PE")) {
	unique.counts.only <- unique.counts.data[,c("Sample","R1_Percent_Unique","R2_Percent_Unique")]	
	#if sample names start with a number, append "x" to names - else get an error.
	if (substring(unique.counts.only$Sample[1], 1, 1) %in% c("0","1","2","3","4","5","6","7","8","9")) { # only need to test one sample name
		unique.counts.only$Sample <- paste0("x",unique.counts.only$Sample)
	}
	unique.counts.only <- melt(unique.counts.only)
	#barplot(unique.counts.only, beside=TRUE, ylim=c(0,100), col=c("red", "darkblue"), border=NA, main=project_name, xlab="Sample", ylab="Percentage of Unique Reads in Original Fastq File", names.arg=c(1:length(unique.counts.data$Sample)), cex.axis=1.75, cex.lab=2, cex.main=2)
	#legend("right", c("R1", "R2"), fill=c("red", "darkblue"), border=NA, bty="n", xpd=TRUE, inset=-0.3, cex=1.5)
	ggplot(unique.counts.only, aes(x=Sample, y=value, fill=variable))+ 
		geom_bar(stat="identity", position="dodge") +
		scale_fill_manual(values=c("navy", "firebrick")) +
		labs(title=project_name, x="Sample", y="Percentage of Unique Reads in Original Fastq File") +
		ylim(0, 100) +
		theme_bw() +
		theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		legend.title = element_text(color="white", size=12),
		legend.text = element_text(size = 16),
            	axis.text.y = element_text(size=14),
            	plot.title = element_text(size=18, hjust=0.5, face="bold"),
            	axis.title.x = element_text(size=14),
            	axis.title.y = element_text(size=16))
	} else {
	ggplot(data = unique.counts.data, aes(x = Sample, y = Percent_Unique)) + 
		geom_bar(stat="identity", fill="firebrick") +
		labs(title=project_name, x="Sample", y="Percentage of Unique Reads in Original Fastq File") +
		ylim(0, 100) +
		theme_bw() +
		theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
            	axis.text.y = element_text(size=14),
            	plot.title = element_text(size=18, hjust=0.5, face="bold"),
            	axis.title.x = element_text(size=14),
            	axis.title.y = element_text(size=16))
}
```

### Plot: Sequence Duplication Level

```{r, eval=T, echo=F, message=FALSE,fig.width=10, fig.height=8}
color.list <- rep(brewer.pal(12,"Paired"), length(sample_names))
par(mai=c(1.02,1,0.82,3)) #bottom, left, top, and right
if (library_type %in% c("PE")) {
	for (i in seq(1, 2*length(sample_names), 2)){
		  sample.index <- i+1
		  if (i==1) {
			 plot(duplicates[-1, sample.index], col=color.list[i], type="o", xlab="Sequence Duplication Level", ylab="Percentage of Total Sequences", main=project_name, ylim=c(0, max(c(100, ceiling(max(duplicates[11, -1]))))), cex.axis=1.75, cex.lab=2, cex.main=2)
			 lines(duplicates[-1, sample.index+1], col=color.list[i], type="o")
		  } else {
			 lines(duplicates[-1, sample.index], col=color.list[i], type="o")
			 lines(duplicates[-1, sample.index+1], col=color.list[i], type="o")
		  }
	}
	legend("topright", sample_names, fill=color.list[seq(1, 2*length(sample_names), 2)], bty="n", border=color.list[seq(1, 2*length(sample_names), 2)], cex=1.1, xpd=TRUE, ncol=2, inset=c(0.05,0))
	} else {
	for (i in seq(1, length(sample_names))){
		  sample.index <- i+1
		  if (i==1) {
			 plot(duplicates[-1, sample.index], col=color.list[i], type="o", xlab="Sequence Duplication Level", ylab="Relative Scale Where Single Reads Have Value 100", main=project_name, ylim=c(0, max(c(100, ceiling(max(duplicates[11, -1]))))), cex.axis=1.75, cex.lab=2, cex.main=2)
		  } else {
			 lines(duplicates[-1, sample.index], col=color.list[i], type="o")
		  }
	legend("topright", sample_names, fill=color.list, bty="n", border=color.list, cex=1.1, xpd=TRUE, ncol=2, inset=c(0.05,0))
	}
}
```

### Bamtools Reads Summary

```{r, eval=T, echo=F, message=FALSE}
bamstats.summary <- bamstats.data
row.names(bamstats.summary)=bamstats.summary$Type
bamstats.summary$Type=NULL
if (library_type %in% c("PE")) { # total read counts from fastq
  total_reads=unique.counts.data$R1_Raw_Reads+total_reads+unique.counts.data$R2_Raw_Reads
  bamstats.summary <- bamstats.summary[!row.names(bamstats.summary)%in%c("Failed QC","Duplicates"), , drop=FALSE]
} else {
  # total read counts from fastq
  total_reads=unique.counts.data$Raw_Reads
  bamstats.summary <- bamstats.summary[!row.names(bamstats.summary)%in%c("Failed QC","Duplicates","Paired-end reads"), , drop=FALSE]
}
bamstats.summary["Total reads",]=total_reads
unmapped_reads <- bamstats.summary["Total reads",] - bamstats.summary["Mapped reads",]
row.names(unmapped_reads) <- "Unmapped reads"
bamstats.summary <- rbind(bamstats.summary, unmapped_reads)
DT::datatable(bamstats.summary, options = list(pageLength = 25))
```


### Bamtools Reads Summary As Percentage of Mapped Reads

```{r, eval=T, echo=F, message=FALSE}
bamstats.percent.table=do.call(rbind,apply(bamstats.summary,1,function(x){round(x/bamstats.summary[1,]*100,2)}))
DT::datatable(bamstats.percent.table, options = list(pageLength = 25))
```

### Percentage of Mapped/Unmapped Reads

```{r, eval=T, echo=F, message=FALSE}
DT::datatable(bamstats.percent.table[c("Mapped reads","Unmapped"),], options = list(pageLength = 25))
```

### Plot: Percentage of Mapped/Unmapped Reads

```{r, eval=T, echo=F, message=FALSE,fig.width=10, fig.height=8}
mapped.percent.for.plot <- rbind(
  data.frame(
    variable=colnames(bamstats.percent.table),
    value=as.numeric(bamstats.percent.table["Mapped reads",]),
    Type=rep("Mapped",ncol(bamstats.percent.table))),
  data.frame(
    variable=colnames(bamstats.percent.table),
    value=as.numeric(bamstats.percent.table["Unmapped reads",]),
    Type=rep("Unmapped",ncol(bamstats.percent.table)))
)
mapped.percent.for.plot$Type <- factor(mapped.percent.for.plot$Type, levels=c("Unmapped", "Mapped")) # order so mapped reads are at the bottom 

ggplot(data = mapped.percent.for.plot, aes(x = variable, y = value, fill=Type)) + 
	geom_bar(stat="identity") +
	scale_fill_manual(values=c("navy", "firebrick")) +
	labs(title=project_name, x="Sample", y="Percentage of Total Reads") +
	ylim(0, 100) +
	theme_bw() +
	theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		legend.title = element_text(color="white", size=12),
		legend.text = element_text(size = 16),
           	axis.text.y = element_text(size=16),
         	plot.title = element_text(size=18, hjust = 0.5, face="bold"),
           	axis.title.x = element_text(size=18),
         	axis.title.y = element_text(size=18))
```


```{r setup, echo=FALSE}

instertsize <- if (library_type %in% c("PE")) {TRUE} else {FALSE}   #use this to replace all the if conditions in subsequent code chunks
```

```{r, eval = instertsize, echo=FALSE}
asis_output("## InsertSizeMetrics Summary<br>") 
```

```{r, eval = instertsize, echo=FALSE}
asis_output("For paired-end data, the Picard Tools CollectInsertSizeMetrics function was used to compute the distribution of insert sizes in the accepted_hits.bam file and create a histogram. Related text files that were saved: ")
```


```{r, eval=T, echo=F, message=FALSE, results='asis'}
if (library_type %in% c("PE")) {
	cat(project_name, "_insertmetrics_summary.txt\n\n")
	}
```

```{r, eval=T, echo=F, message=FALSE}
# Insert Size Summary
if (library_type %in% c("PE")) {
	insert.sum.data <- apply(insert.summary.data[c(1:7), c(2:length(names(insert.summary.data))), drop=FALSE], 2, as.numeric)
	row.names(insert.sum.data) <- insert.summary.data[c(1:7), 1]
	table.digits <- matrix(c(rep(0,4),rep(2,2),0), nrow=7, ncol=length(names(insert.summary.data)))
	DT::datatable(insert.sum.data, options = list(pageLength = 25))
	#pander::pandoc.table(insert.sum.data, split.table = Inf)
	}
```

```{r, eval=T, echo=F, message=FALSE, fig.width=12, fig.height=10}
if (library_type %in% c("PE")) {
	par(mai=c(1.02,1,0.82,0.42))
	barplot(insert.sum.data[1, , drop=FALSE], ylim=c(0, max(insert.sum.data[1, ])+100), col=c("red"), border=NA, main=project_name, xlab="Sample", ylab="Median Insert Size", names.arg=c(1:length(sample_names)), cex.axis=0.9)
	}
```

```{r, eval=T, echo=F, message=FALSE, fig.width=12, fig.height=10}
par(mai=c(1.02,1,0.82,2)) #bottom, left, top, and right
if (library_type %in% c("PE")) {
	delta <- 1/(2*length(sample_names))
	c <- rep(brewer.pal(12,"Paired"), length(sample_names))
	y.max <- max(insert.metrics.data[ ,-1, drop=FALSE], na.rm=TRUE)
	for (i in c(1:length(sample_names))){
		  sample.index <- i+1
		  if (i==1) {
			 plot(insert.metrics.data[ ,1], insert.metrics.data[ ,sample.index], type="l", col=c[i], xlab="Insert Size", ylab="Read Count", main=project_name, bty='L', ylim=c(0,y.max), xlim=c(0, 2000), cex.axis=1.75, cex.lab=2, cex.main=2)
		  } else {
			 shifted = insert.metrics.data[ ,1]+delta*(i-1)
			 lines(shifted, insert.metrics.data[ ,sample.index], col=c[i])
		  }
	}
	legend("right", sample_names, fill = c, bty="n", border=c, cex=1.1, ncol=2, inset=c(-0.05,0))


	}
```

## Reads per Chromosome

Samtools produces a summary document that includes the number of reads mapped to each chromosome. Related text files that were saved:
```{r, eval=T, echo=F, message=FALSE, results='asis'}
cat("\n\n", project_name, "_counts.txt\n\n")
```

```{r, eval=T, echo=F, message=FALSE, warning=FALSE, fig.width=10,fig.height=8}
sample_tmp=names(counts.data)[!names(counts.data)%in%c("Chromosome","Length")]
counts.data$Chromosome=factor(counts.data$Chromosome, levels=c(as.character(seq(22)),"X","Y","Other","rRNA"))
counts.data.melted <- counts.data %>%
  dplyr::select(-Length) %>%
  tidyr::gather(Sample, counts, -Chromosome)
c <- rep(brewer.pal(12,"Paired"), length(sample_names))

ggplot(data = counts.data.melted, aes(x = Chromosome, y = counts, fill=Sample)) + 
  geom_bar(stat="identity", position = "dodge") +  #note stacked is default for ggplot2, so must specify "dodge" to get side-by-side bars
  labs(title=project_name, x="Chromosome", y="Read Counts") +
		theme_bw() +
    scale_fill_manual(values=c[seq(sample_tmp)]) +
		theme(
		  axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		  legend.title = element_text(color="white", size=12),
			legend.text = element_text(size = 16),
		  axis.text.y = element_text(size=16),
      plot.title = element_text(size=20, hjust = 0.5, face="bold"),
		  axis.title.x = element_text(size=18),
      axis.title.y = element_text(size=18))
```

### Mapped Reads to Reference Genome

```{r, eval=T, echo=F, message=FALSE}
counts.data.tb <- counts.data
row.names(counts.data.tb) <- counts.data.tb$Chromosome
counts.data.tb$Chromosome=NULL
counts.data.tb$Length=NULL
counts.data.tb <- counts.data.tb[c(as.character(seq(22)),"X","Y","Other","rRNA"),]
#Add in the total row at bottom
count.total <- colSums(counts.data.tb)
counts.data.tb["Total",]=count.total
DT::datatable(counts.data.tb, options = list(pageLength = 30))
```


### Percent of Total Reads Mapped to Reference Genome

```{r, eval=T, echo=F, message=FALSE}
counts.percent.table <- do.call(rbind,apply(counts.data.tb,1,function(x){round(x/counts.data.tb["Total",]*100, 2)}))
DT::datatable(counts.percent.table, options = list(pageLength = 30))
```


## Principal Component Analysis (PCA) Plot

```{r prep_diffbind_csv, eval=T, echo=F, message=F, warning=F, results="hide"}
# Prepare sample sheet
coldata <- read.table(sample_info_file,header=T,sep='\t')

# Create bam read columns
coldata$bamReads=paste0(path_start,coldata$Sample,'/bwa_out/',coldata$Sample,'.bam')
bamreads=coldata$bamReads[which(!coldata$Antibody%in%"Input")]
nobamReads=bamreads[!sapply(bamreads,file.exists)]
if (length(nobamReads)>1) {stop('Bam read file(s) do not exists: ',paste(nobamReads,collapse=', '))}

# Create bam control columns
coldata$bamControl=sapply(coldata$Input, function(x){
if (is.na(x)){NA} else {paste0(path_start, as.character(x),'/bwa_out/',x,'.bam')}
})
if (any(!is.na(coldata$Input))) {
bamcontrols=coldata$bamControl[which(!coldata$Antibody%in%"Input")&(!is.na(coldata$Input))]
nobamControl=bamcontrols[!sapply(bamcontrols,file.exists)]
if (length(nobamControl)>1) {stop('Bam control file(s) do not exists: ',paste(nobamControl,collapse=', '))}}

# Create peak bed columns
coldata$Peaks=paste0(path_start,coldata$Sample,'/macs2_out/',coldata$Sample,'.blackfilt.bed')
bedpeaks=coldata$Peaks[which(!coldata$Antibody%in%"Input")]
nobed=bedpeaks[!sapply(bedpeaks,file.exists)]
if (length(nobed)>1) {stop('Peak bed file(s) do not exists: ',paste(nobed,collapse=', '))}

#modify to diffbind input format
input_csv <- coldata %>%
  dplyr::filter(!Antibody%in%"Input") %>%
  dplyr::mutate(SampleID=Sample, Factor=Antibody, ControlID=Input, PeakCaller="bed") %>%
  dplyr::mutate(Condition=Status) %>%
  dplyr::group_by(Status,Treatment) %>%
  dplyr::mutate(Replicate=1:length(Treatment)) %>%
  dplyr::ungroup() %>%
  dplyr::select(SampleID, Tissue, Factor, Condition, Treatment, Replicate, bamReads, ControlID, bamControl, Peaks, PeakCaller) %>%
  as.data.frame() %>%
  droplevels()
write.csv(input_csv,paste0(project_name,".sampleinfo.csv"),row.names=F)
```

Perform PCA using read scores from DiffBind. DiffBind will compute read counts for all samples. This process takes a while. Use peaks at least shared by two samples.

```{r diffbind_func, echo=F}
diffbind_func <- function(){
  dat.bind <- dba(sampleSheet=paste0(project_name,".sampleinfo.csv"))
  # obtain counts of peaks that at least shared by two samples
  dat.bind <- dba.count(dat.bind, minOverlap=2) # this step takes a while
  # saveRDS(dat.bind, paste0(project_name,"_count.RDS"))
  # retrieve read scores
  dat.scores=dba.peakset(dat.bind, bRetrieve=T, DataType=DBA_DATA_FRAME)[-c(1:3)]
  return(dat.scores)
}
```

```{r diffbind_count, eval=T, echo=F, message=F, warning=F, results="hide"}
dat.scores=diffbind_func()
```

```{r pca_func, echo=F, warning=F, message=F}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # calculate the variance for each gene
  rv <- rowVars(m)
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs. Rory Stark: DiffBind doesn't transpose the matrix.
  #pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pca <- prcomp(raw.data.pca, retx = TRUE, center = TRUE, scale = FALSE)
  pc <- data.frame(pca$rotation)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
shapes=seq(25)
pcaplot_func <- function(pc, group_var) { # group_var: column name for a specific group
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=sapply(row.names(pc),function(x)coldata[which(coldata$Sample%in%x),group_var])
  )
  df=droplevels(df)
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point(size=3, shape=1) + theme_bw() + scale_color_manual(group_var,values=colours[seq(unique(df$group))],na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("Tissue", "Donor", "Antibody", "Treatment", "Status")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(coldata)] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    nlevel=nlevels(coldata[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var)
    }
  }
  return(plot_list)
}
```

Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=as.matrix(dat.scores))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

PCA plots are generated using the first two principle components colored by known factors (e.g. treatment/disease conditions, tissue, and donors), visualizing similarities between arrays and these similarities' correlation to batch effects.

```{r pca_plot, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


```{r sessioninfo, echo=F}
pander(sessionInfo())
```

